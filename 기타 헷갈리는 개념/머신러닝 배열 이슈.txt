x 축은 첫번째 특성, y 축은 두번째 특성.

mglearn.discrete_scatter(X[:,0], X[:,1], y)
mglearn.discrete_scatter(x축, y축, 값)

x축과 y축도 각각의 값을 가지고 있을 텐데, 이게 그냥 '축'으로서의 역할만 하는듯/ 따라서 이 경우에는 분류모델이 될 것이다. y가 연속형 자료가 아니라, class를 나타내는 이산형 자료일 것.

즉, y의 값은 진짜 숫자가 아닐 것이라는 것.
ex) 0 = 대학교 1학년 2 = 대학교 2학년 3 = ...
0 = 음성 1 = 양성


z축까지 넣는다고 가정하고 요소를 4개 넣어버리면, 3차원으로 그래프가 그려지는 것이 아니라, 2차원 안에 데이터를 욱여넣어서 이상한 그래프가 평면상에 그려져 버림.

따라서 그래프 그릴 때는 2개의 특성 데이터를 축으로 잡고 y축이 어디에 분포하는가를 그리는 것이 맞음. (x1 은 1이고 x2가 2인 곳에 y(3)값이 있고, ..., x1은 10이고 x2가 25인 곳에 y(0)값이 있다)

특성이 하나만 있어도 모델링은 당연히 가능하다. y = wx1 + b 와 같은 식이 만들어지니까.

단, y가 연속형 자료일 경우에는 어느 정도 그래프가 평범하게 그려지지만, y가 이산형 자료일 경우에는 그래프가 약간 이상하게 그려지는 것이 당연.

2차원으로 자꾸 만드는 이유는, 2차원 이상의 고차원 데이터의 경우 모델링은 가능하지만 우리가 시각적으로 보기가 쉽지 않기 때문이다.

1차원의 데이터를 굳이 2차원으로 만드는 것은, 
축을 반드시 지정해 주어야 하는 mglearn.discrete.scatter의 특성 때문인듯?

즉, 모델링 학습이 되고 안되고의 문제가 아니라 시각화의 문제인 것.